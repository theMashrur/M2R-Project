{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparison(X, y, multiclass=False, red_perf=False):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    svm = SVC()\n",
    "    nb = GaussianNB()\n",
    "    ada_boost = AdaBoostClassifier()\n",
    "    grad_boost = GradientBoostingClassifier()\n",
    "    classifiers = [rf, nb, ada_boost, grad_boost]\n",
    "\n",
    "    results = []\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict(x_test)\n",
    "        # Use weighted F1 score across multiclass inputs, otherwise default binary score\n",
    "        if multiclass:\n",
    "            results.append([accuracy_score(y_test, predictions), f1_score(y_test, predictions, average='weighted')])\n",
    "        else:\n",
    "            results.append([accuracy_score(y_test, predictions), f1_score(y_test, predictions)])\n",
    "\n",
    "    # Scale data for use in SVMs so larger/more spread variables do not dominate (also improves runtime)\n",
    "    scaler = StandardScaler().fit(x_train)\n",
    "    x_train_std = scaler.transform(x_train)\n",
    "    x_test_std = scaler.transform(x_test)\n",
    "    svm.fit(x_train_std, y_train)\n",
    "    svm_pred = svm.predict(x_test_std)\n",
    "    if multiclass:\n",
    "            results.append([accuracy_score(y_test, svm_pred), f1_score(y_test, svm_pred, average='weighted')])\n",
    "    else:\n",
    "            results.append([accuracy_score(y_test, svm_pred), f1_score(y_test, svm_pred)])\n",
    "\n",
    "    return pd.DataFrame(results, [\"RF\", \"Naive Bayes\", \"AdaBoost\", \"GradientBoost\", \"SVM\"], [\"Accuracy\", \"F1 Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "heart = pd.read_csv(\"../Datasets/heart_cleveland_upload.csv\")\n",
    "y_heart = heart[\"condition\"]\n",
    "X_heart = heart.drop(\"condition\", axis=1)\n",
    "stars = pd.read_csv(\"../Datasets/star_classification.csv\")\n",
    "y_stars = stars[\"class\"]\n",
    "X_stars = stars.drop(\"class\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy  F1 Score\n",
      "RF             0.973684  0.973645\n",
      "Naive Bayes    0.973684  0.973645\n",
      "AdaBoost       0.921053  0.920936\n",
      "GradientBoost  0.973684  0.973645\n",
      "SVM            0.947368  0.947368\n"
     ]
    }
   ],
   "source": [
    "print(classifier_comparison(X_iris, y_iris, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy  F1 Score\n",
      "RF              0.97988  0.979736\n",
      "Naive Bayes     0.60228  0.480350\n",
      "AdaBoost        0.78924  0.731177\n",
      "GradientBoost   0.97756  0.977346\n",
      "SVM             0.96364  0.963459\n"
     ]
    }
   ],
   "source": [
    "print(classifier_comparison(X_stars, y_stars, True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy  F1 Score\n",
      "RF             0.840000  0.818182\n",
      "Naive Bayes    0.853333  0.845070\n",
      "AdaBoost       0.840000  0.823529\n",
      "GradientBoost  0.800000  0.776119\n",
      "SVM            0.826667  0.811594\n"
     ]
    }
   ],
   "source": [
    "print(classifier_comparison(X_heart, y_heart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
