{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparison(X, y, multiclass=False, red_perf=False):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    svm = SVC()\n",
    "    nb = GaussianNB()\n",
    "    ada_boost = AdaBoostClassifier()\n",
    "    grad_boost = GradientBoostingClassifier()\n",
    "    classifiers = [rf, nb, ada_boost, grad_boost]\n",
    "\n",
    "    results = []\n",
    "    for classifier in classifiers:\n",
    "        classifier.fit(x_train, y_train)\n",
    "        predictions = classifier.predict(x_test)\n",
    "        # Use weighted F1 score across multiclass inputs, otherwise default binary score\n",
    "        if multiclass:\n",
    "            results.append([accuracy_score(y_test, predictions), precision_score(y_test, predictions, average='weighted'), recall_score(y_test, predictions, average='weighted')])\n",
    "        else:\n",
    "            results.append([accuracy_score(y_test, predictions), precision_score(y_test, predictions), recall_score(y_test, predictions)])\n",
    "\n",
    "    # Scale data for use in SVMs so larger/more spread variables do not dominate (also improves runtime)\n",
    "    scaler = StandardScaler().fit(x_train)\n",
    "    x_train_std = scaler.transform(x_train)\n",
    "    x_test_std = scaler.transform(x_test)\n",
    "    svm.fit(x_train_std, y_train)\n",
    "    svm_pred = svm.predict(x_test_std)\n",
    "    if multiclass:\n",
    "            results.append([accuracy_score(y_test, svm_pred), precision_score(y_test, svm_pred, average='weighted'), recall_score(y_test, svm_pred, average='weighted')])\n",
    "    else:\n",
    "            results.append([accuracy_score(y_test, svm_pred), precision_score(y_test, svm_pred), recall_score(y_test, svm_pred)])\n",
    "\n",
    "    return pd.DataFrame(results, [\"RF\", \"Naive Bayes\", \"AdaBoost\", \"GradientBoost\", \"SVM\"], [\"Accuracy\", \"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "heart = pd.read_csv(\"../Datasets/heart_cleveland_upload.csv\")\n",
    "y_heart = heart[\"condition\"]\n",
    "X_heart = heart.drop(\"condition\", axis=1)\n",
    "stars = pd.read_csv(\"../Datasets/star_classification.csv\")\n",
    "y_stars = stars[\"class\"]\n",
    "X_stars = stars.drop(\"class\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy  Precision    Recall\n",
      "RF             0.947368   0.947368  0.947368\n",
      "Naive Bayes    0.921053   0.921952  0.921053\n",
      "AdaBoost       0.868421   0.868758  0.868421\n",
      "GradientBoost  0.894737   0.898661  0.894737\n",
      "SVM            0.973684   0.975439  0.973684\n"
     ]
    }
   ],
   "source": [
    "print(classifier_comparison(X_iris, y_iris, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy  Precision   Recall\n",
      "RF              0.97916   0.979046  0.97916\n",
      "Naive Bayes     0.59648   0.442431  0.59648\n",
      "AdaBoost        0.63756   0.645962  0.63756\n",
      "GradientBoost   0.97844   0.978347  0.97844\n",
      "SVM             0.95760   0.957872  0.95760\n"
     ]
    }
   ],
   "source": [
    "print(classifier_comparison(X_stars, y_stars, True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy  Precision    Recall\n",
      "RF             0.786667   0.937500  0.681818\n",
      "Naive Bayes    0.813333   0.875000  0.795455\n",
      "AdaBoost       0.786667   0.937500  0.681818\n",
      "GradientBoost  0.773333   0.909091  0.681818\n",
      "SVM            0.773333   0.885714  0.704545\n"
     ]
    }
   ],
   "source": [
    "print(classifier_comparison(X_heart, y_heart))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
